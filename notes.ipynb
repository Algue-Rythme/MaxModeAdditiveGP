{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "X, Y = observations\n",
    "X = (x1 ... xn)\n",
    "contraintes = string \n",
    "kernel = rbf \n",
    "partition des variables\n",
    "subdivision par variable\n",
    "\n",
    "\n",
    "Pour chaque bloc de la partition\n",
    "  Pour chaque variable du bloc \n",
    "    Prendre la subdivision et calculer les fonction \"chapeau\" de base associées (1D)\n",
    "    => évaluer tout les xi dans X sur ces fonctions de base 1D\n",
    "  => Tensorization pour avoir l'evaluation des xi sur les fonctions de base du bloc\n",
    "  (voir les maths: c'est un produit)\n",
    "\n",
    "Pour chaque bloc B\n",
    "  m_i = taille subdivision \n",
    "  taille_base_bloc = m = prod_i m_i\n",
    "  phi_B(X) = tensor of shape (n, taille_base_bloc)\n",
    "\n",
    "Phi(X) = (Phi_1(X) ... Phi_{num_blocks}(X))  \n",
    "\n",
    "tau = parameter regul \n",
    "\n",
    "k_S(ksi, ksi) = tensor of shape (sum_blocks taille_base_bloc, sum_blocks taille_base_bloc)\n",
    "=> trop gros don't implement\n",
    "\n",
    "k_{B}(ksi, ksi) = tensor of shape (taille_base_bloc, taille_base_bloc)\n",
    "\n",
    "## background\n",
    "pour chaque variable\n",
    "je regarde l'espace 1D associé\n",
    "l'espace des fonctions sur cet espace 1D\n",
    "je construits une base sur cet espace de fonctions de taille m_i\n",
    "les éléments de base sont en bijection avec l'espace 1D\n",
    "\n",
    "pour chaque block \n",
    "les éléments de base (obteni par tensorization) sont en bijection avec l'espace taille_bu_block-D \n",
    "\n",
    "nouvel ingredient: \n",
    "  kernel K_var 1D sur chaque variable (hyper-param) \n",
    "  kernel K_block taille_block-D sur chaque block par tensorization  (resultat!)\n",
    "\n",
    "k_{B}(ksi, ksi)_ij = multi-index i, multi-index j,\n",
    "                     et j'evalue le kernel_block sur les points ti et tj\n",
    "\n",
    "!!! warning: ne pas confondre le vecteur de base n°i et sa \"position\" i \n",
    "\n",
    "Voir equation (30): inversion on necessaire car on veut l'inverse de la matrice de covariance\n",
    "Pourquoi ?\n",
    "\n",
    "ksi = argmin_{x in convex} (x-mu) Cov^{-1} (x-mu)\n",
    "remark: convex défini par les contraintes \n",
    "\n",
    "ksi = tensor of shape (num_vecteur_base,)\n",
    "num_vecteur_base = sum_B taille_base_block_B\n",
    "\n",
    "Fonction predictrice y(x) = ksi^T Phi(x)  # TODO reecrire par block\n",
    "Remark: comme Phi(X) avec un dataset singleton X={x}\n",
    "\n",
    "MaxMod: update les h-params de façon greedy (h-params: TODO)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
